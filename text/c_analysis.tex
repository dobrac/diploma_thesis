In this section I am going to first introduce what Protocol Buffers are.
Then, I am going to analyze existing solutions of website documentations with the ability to call APIs for Protocol Buffers, GraphQL and RESTful APIs.
I will start with Protocol Buffers, then I will move and explore the solutions to GraphQL and finally I will analyze RESTful API\@.


\section{Protocol Buffers}
Protocol Buffers are a mechanism for serializing structured data.
The are language-neutral and platform-neutral.
They encompass:
\begin{itemize}
    \item definition language,
    \item compiler-generated code,
    \item language-specific runtime libraries,
    \item serialization format.
\end{itemize}
The definition language is used to define data structures, expressed in .proto files.
The compiler-generated code is used to enable interaction with the defined data structures in a specific programming language.
The language-specific runtime libraries are used to facilitate the serialization and deserialization of data according to the Protocol Buffer format.
The serialization format is a compact binary format used for storing Protocol Buffer data in files or transmitting it across network connections.
\cite{protobuf-overview}

The mechanism of typical workflow is described in the figure~\ref{fig:protobuf-mechanism}.
For the purpose of this work, my main focus will be on generating the code (and website documentation) from the .proto files and using the generated code to interact with the final APIs.
\begin{figure}[hbt!]
    \centering
    \captionsetup{justification=centering}
    \includegraphics[width=0.8\textwidth]{images/protocol-buffers-concepts.png}
    \caption{Protocol Buffers Workflow~\cite{protobuf-overview}}
    \label{fig:protobuf-mechanism}
\end{figure}

There are two language versions of Protocol Buffers, version 2 and version 3.
The versions share the same basic concepts, use the same syntax, but version 3 improves on version 2 in several ways~\cite{protobuf-proto3}.
As this work is focused on the latest technologies, I will be focusing on version 3 of Protocol Buffers.
If no specific version is mentioned, it is assumed that version 3 is used.

\subsection{Structures}
The basic keywords in Protocol Buffers are \textit{message}, \textit{enum}, \textit{service}, \textit{method} and \textit{package}.
The \textit{message} is used to define a data structure.
The \textit{enum} is used to define a set of named constants.
The \textit{service} is set of \textit{methods} that can be called remotely.
And, the \textit{package} type is used to define a namespace for the defined \textit{messages}, \textit{enums} and \textit{services}.
\cite{protobuf-proto3}

\subsubsection{Message}
Messages are used to define data structures.
They are defined using the \textit{message} keyword followed by the name of the message and a block of fields.
Each field has a name, a type and a unique number across all fields in the \textit{message}.
The type of a field can be a scalar type or another \textit{message} type.
The possible scalar types are described in the table~\ref{tab:protobuf-scalar-types} with their C++ counterparts.
The unique number is used to identify the field in the binary encoding.
Reusing the same number for different fields is therefore highly discouraged.
To avoid this, there is a \textit{reserved} keyword which I will describe later.
\cite{protobuf-proto3}

\begin{table}[hbt!]
    \centering
    \captionsetup{justification=centering}
    \begin{tabular}{|l|l|}
        \hline
        .proto   & C++    \\ \hline
        double   & double \\ \hline
        float    & float  \\ \hline
        int32    & int32  \\ \hline
        int64    & int64  \\ \hline
        uint32   & uint32 \\ \hline
        uint64   & uint64 \\ \hline
        sint32   & int32  \\ \hline
        sint64   & int64  \\ \hline
        fixed32  & uint32 \\ \hline
        fixed64  & uint64 \\ \hline
        sfixed32 & int32  \\ \hline
        sfixed64 & int64  \\ \hline
        bool     & bool   \\ \hline
        string   & string \\ \hline
        bytes    & string \\ \hline
    \end{tabular}
    \caption{Scalar Types in Protocol Buffers~\cite{protobuf-proto3}}
    \label{tab:protobuf-scalar-types}
\end{table}

% Numbering
% Repeated
% Map
% Optional
% One Of
% Options
% reserved

Additional properties can be added to fields or types to alter their behaviour.
The possibilities are \textit{reserved}, \textit{optional}, \textit{repeated}, \textit{map}, and \textit{oneof}.
\cite{protobuf-proto3}

The \textit{reserved} keyword is used to reserve a field number, preventing it from being used in the future.
This is useful when a field is removed from a message and the field number should not be reused.
You can specify a single field number, a range of field numbers, or a list of field numbers and ranges.
\cite{protobuf-proto3}

In Protocol Buffers version 3, fields are inherently optional, with omitted fields assuming their default values.
This can create ambiguity when differentiating between a missing field and one explicitly set to its default.
The \textit{optional} keyword resolves this by providing a mechanism to explicitly mark fields as optional and track whether they have been set, even if the value is the default.
\cite{protobuf-proto3}

The \textit{repeated} keyword is used to define fields that can hold multiple values of the same type.
This is analogous to arrays or lists in common programming languages.
A repeated field allows you to represent collections of data within your message structure.
For example, a \textit{message} representing an order might have a \textit{repeated} field for line items, allowing multiple products within a single order.
Protocol Buffers offer efficient encoding mechanisms for repeated fields, making them suitable for representing ordered lists of data.
\cite{protobuf-proto3}

The \textit{map} keyword is employed to define fields encompassing key-value pairs, akin to dictionaries or hashmaps in programming contexts.
A \textit{map} field allows the flexible association of related data without the constraints of a rigid structure.
For instance, a product attribute message could leverage a \textit{map} field where keys denote attribute names (``color'', ``size'') and their corresponding values provide the descriptions (``red'', ``large'').
\cite{protobuf-proto3}

And finally, the \textit{oneof} keyword provides a mechanism to define a message field where only one of several sub-fields can be set at a time.
This is valuable when the \textit{message} needs to represent mutually exclusive data variations.
For example, a payment\_method field within a \textit{message} could use a \textit{oneof} to support different payment types like credit\_card, debit\_card, or paypal.
Setting one of these sub-fields automatically clears any previously set values within the \textit{oneof}.
This helps conserve memory and enforces a clear structure for alternative data representations.
\cite{protobuf-proto3}

\subsubsection{Enum}
Another type of structure is \textit{enum}.
It is used to define a set of named constants.
The constants are defined using the \textit{enum} keyword followed by the name of the \textit{enum} and a block of constants with their numeric values.
The special numeric value 0 is used as the default value.
Therefore, it is necessary, that the first constant has the value 0.
\cite{protobuf-proto3}

The \textit{enum} has a special option called \textit{allow\_alias} which allows having the same numeric values for multiple names.
This is useful when the same value is used in different contexts.
\cite{protobuf-proto3}

\subsubsection{Service and Method}
The \textit{service} is used to define a set of \textit{methods} that can be called remotely.
It is defined using the \textit{service} keyword followed by the name of the \textit{service} and a block of \textit{methods}.
Each \textit{method} has a name, request and response \textit{message} type.
The \textit{method} can also have a \textit{stream} keyword to define a streaming of request, response or both.
\cite{protobuf-proto3}

Streaming is a feature that allows the client and server to send a sequence of \textit{messages} back and forth until the stream is closed.
This is useful when the client or server needs to send a large number of \textit{messages} and does not know the exact number of \textit{messages} in advance.
\cite{protobuf-proto3}

There are four types of gRPC calls.
When no streaming is involved, it is called \textit{unary} call.
When the request is streamed, it is called \textit{client-streaming} call.
When the response is streamed, it is called \textit{server-streaming} call.
And when both request and response are streamed, it is called \textit{bidirectional-streaming} call.
\cite{grpc-core-concept}

\subsubsection{Packages}
The \textit{package} is used to define a namespace for the defined \textit{messages}, \textit{enums} and \textit{services} in the .proto file.
It is present at the beginning of the file using the \textit{package} keyword followed by the name of the \textit{package}.
For the code generation, the \textit{package} may not be considered.
This is especially true for the Java.
Because of that, there is a \textit{java\_package} option that can be used to define the package for the generated code.
This option is defined at the file level.
\cite{protobuf-proto3}

The other option to differentiate \textit{messages} names is using nested types.
The \textit{message} can be defined inside another \textit{message}.
This is useful when the \textit{message} is used only in the context of the parent \textit{message} or is meaningful only with the parent \textit{message} context.
\cite{protobuf-proto3}

Both \textit{package} and nested types are used to avoid name conflicts and can be used using the dot notation between name.

\subsection{Comments}
The .proto files can contain comments.
The comments can be single-line or multi-line.
The single-line comments are started with the \textit{//} characters.
The multi-line comments are started with the \textit{/*} characters and ended with the \textit{*/} characters.
The comments can be used to describe the purpose of the \textit{message}, \textit{enum}, \textit{service}, \textit{method} or \textit{field}.
The comments can also be used to describe the purpose of the \textit{package} or the whole file.
\cite{protobuf-proto3}

\subsection{Code Generation}
The .proto files are used to generate the code for the specific programming language.
The code generation can be done using various tools, the recommended one is the Protocol Compiler (protoc).
It is used to generate the code for the C++, C\#, Dart, Go, Java, Python, Ruby, and JavaScript.
An example usage is described in the code snippet~\ref{code:protobuf-protoc}.
Required classes and types are then generated and the gRPC APIs can be called without any extra coding work.
\cite{protobuf-proto3}

\begin{lstlisting}[language=bash, caption={Protocol Buffers Code Generation~\cite{protobuf-proto3}}, label={code:protobuf-protoc}]
protoc --proto_path=IMPORT_PATH --java_out=DST_DIR path/to/file.proto
\end{lstlisting}

\subsection{gRPC-web}
The gRPC is built on HTTP/2, using features like HTTP/2 framing~\cite{grpc-protocol-http2}.
As the HTTP/2 framing is not, and probably never be, directly exposed by any browser, the gRPC-Web protocol exists~\cite{grpc-protocol-web}.

The design goals of the gRPC-Web are:
\begin{itemize}
    \item adopt the same framing as gRPC whenever possible,
    \item decouple from HTTP/2 framing,
    \item support text stream for cross-browser support~\cite{grpc-protocol-web}.
\end{itemize}

The gRPC-Web is adding a proxy in between the server and the browser.
The communication works as follows.
The browser sends a request to the proxy using the gRPC-Web protocol.
The proxy translates the gRPC-Web protocol to the gRPC protocol and sends the request to the server.
The server processes the request and sends the response back to the proxy.
The proxy translates the gRPC protocol to the gRPC-Web protocol and sends the response back to the browser.
The browser processes the response and the communication is done.
\cite{grpc-protocol-web}

The default proxy implementation is the Envoy\footnote{\url{https://www.envoyproxy.io/}} proxy.
It supports the gRPC-Web protocol out of the box.
Other options are, but not only, gRPC-web Go proxy\footnote{\url{https://github.com/improbable-eng/grpc-web/tree/master/go/grpcwebproxy}}, APISIX\footnote{\url{https://apisix.apache.org/blog/2022/01/25/apisix-grpc-web-integration/}}, and Nginx\footnote{\url{https://www.nginx.com/}}.


Because of the proxy and browser implementation, there are few differences and current limitations of the gRPC-Web~\cite{grpc-web}.
The main and the most important one is the streaming support.
At this point in time, the gRPC-Web does not support client-side streaming (and effectively bi-directional streaming).
It supports only unary calls and server-side streaming.
The client-side streaming is planned for the future, based on the streaming roadmap in year 2023+, but it has not been implemented yet~\cite{grpc-web-streaming-roadmap}.

\subsection{gRPC Reflection}
The gRPC protocol uses binary encoding.
Therefore, it is not possible to query the server without knowing the protobuf definition of the service and both request and response messages prior of the request.
The gRPC reflection is a way to get this information using standardized gRPC service that allows other clients to query the server for the protobuf-defined APIs.
It includes all necessary information about the services, methods, enums and messages.
This information can be used to encode requests, query the server, and decode responses.
It is used by debugging tools such as grpcurl\footnote{\url{https://github.com/fullstorydev/grpcurl}}.
The gRPC reflection service is not exposed by default, so it has to be enabled in the server configuration explicitly.
The support for it varies across different gRPC implementations in different programming languages.
\cite{grpc-reflection}


\section{Documentation Websites}
In this section I well explore the most popular solutions for creating documentation websites for gRPC, GraphQL and RESTful APIs.
For each solution I will evaluate their features and issues.
I will start with gRPC, then I will move to GraphQL and finally I will analyze RESTful APIs.
At the end, I will summarize the findings, discuss the issues and propose a solution for the static web generator.

\subsection{Protocol Buffers}

\subsubsection{Wombat}

\subsubsection{bloomrpc}

\subsubsection{GenDocu and grpc-docs}

\subsubsection{grpcui}

\subsubsection{proto2asciidoc}

\subsubsection{protoc-gen-doc}

\subsubsection{letmegrpc}

\subsubsection{grpc-swagger}

\subsubsection{grpc-gateway}

\subsubsection{Postman}

\subsection{GraphQL}

\subsubsection{graphdoc}

\subsubsection{graphql-playground}

\subsubsection{graphiql}

\subsection{RESTful API}

\subsubsection{Swagger UI}

\subsection{Summary}

\subsubsection{Issues}


\section{Requirements}
On the basis of the previously described problems and main requirements, I have compiled functional and non-functional requirements covering the required functionality of the static web generator.

\subsection{Functional}
% Co má systém umět

%\subsubsection{F1 -- Pomocník pro inicializaci obrazu softwaru Syllabus Plus}
%Pro inicializaci obrazu softwaru Syllabus Plus a další práci s daty je potřeba zadat informace o daném semestru.
%Správné nastavení je klíčové pro korektní plánování časových lístků.

\subsection{Non-Functional}

%\subsubsection{N1 -- Aplikace s grafickým uživatelským rozhraním}
%Aplikace by měla mít grafické uživatelské rozhraní pro práci s daty.
%Uživatel by tak měl být schopen obsluhovat aplikaci sám bez pomoci další osoby.


\section{Use Cases}


%\begin{figure}
%    \centering
%    \captionsetup{justification=centering}
%    \includegraphics[width=1.0\textwidth]{use-case-diagram}
%    \caption{Diagram případů užití}
%    \label{fig:use-case-diagram}
%\end{figure}

%\subsection{UC1 -- Inicializace obrazu softwaru Syllabus Plus}
%Rozvrhář spustí software Syllabus Plus a začne s inicializací nového obrazu.
%Během inicializace se mu zobrazí dialog pro nastavení začátku semestru, vyučované dny, začátek a konec hodin, počet hodin za den a počet týdnů na semestr.
%Rozvrhář otevře aplikaci pro převod a nastaví semestr, který se využije pro načítání dat ze systému KOS\@.
%Zobrazí si jakým způsobem má položky nastavit, aby byla data správně reprezentována (například při plánování časových lístků).
%Formulář vyplní podle získaných dat z aplikace a inicializuje obraz.
%V případě, že se rozvrhář splete, musí aktuální obraz smazat a začít vytvářet nový od začátku.
%Jinak je inicializace úspěšně dokončena.


\section{Requirements to Use Cases Mapping}
I have compiled a table of requirements and use cases mapping (see table~\ref{tab:use_cases}) to verify that all requirements are covered by at least one use case and that no use case is unnecessary.
The table shows that all requirements are covered.

\begin{table}[hbt!]
    \centering
    \captionsetup{justification=centering}
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|}
        \hline
        & \multicolumn{15}{c|}{Use Cases} \\ \hline
        & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \\ \hline
        F1  & x &   &   &   &   &   &   &   &   &    &    &    &    &    &    \\ \hline
        F2  &   &   & x &   &   &   &   &   &   &    &    &    &    &    &    \\ \hline
        F3  &   &   &   & x &   &   &   &   &   &    &    &    &    &    &    \\ \hline
        F4  &   &   &   &   &   &   &   &   &   &    &    &    &    &    & x  \\ \hline
        F5  &   &   &   &   & x &   &   &   &   &    &    &    &    &    &    \\ \hline
        F6  &   & x &   &   &   &   &   & x &   &    &    & x  & x  &    &    \\ \hline
        F7  &   & x &   &   &   &   &   &   &   &    &    & x  &    &    &    \\ \hline
        F8  &   &   &   &   &   &   &   &   &   &    &    &    & x  &    &    \\ \hline
        F9  &   & x &   &   &   &   &   &   &   &    & x  &    &    &    &    \\ \hline
        F10 &   & x &   &   &   &   &   &   &   &    &    &    &    &    &    \\ \hline
        F11 &   &   &   &   &   &   &   &   & x & x  &    &    &    &    &    \\ \hline
        F12 &   & x &   &   &   &   &   &   &   &    &    &    &    &    &    \\ \hline
        F13 &   &   &   &   &   &   &   &   &   & x  &    &    &    &    &    \\ \hline
        F14 &   &   &   &   &   &   &   & x & x & x  &    & x  & x  &    &    \\ \hline
        F15 &   &   &   &   &   &   &   & x & x & x  &    & x  &    &    &    \\ \hline
        F16 &   &   &   &   &   &   &   & x & x & x  &    & x  & x  &    &    \\ \hline
        F17 &   &   &   &   &   & x & x &   &   &    &    &    &    &    &    \\ \hline
        F18 &   &   &   &   &   & x &   &   &   & x  &    &    &    & x  &    \\ \hline
        F19 & x &   &   &   &   &   &   &   &   &    &    &    &    &    &    \\ \hline
    \end{tabular}
    \caption{Requirements to Use Cases Mapping}
    \label{tab:use_cases}
\end{table}